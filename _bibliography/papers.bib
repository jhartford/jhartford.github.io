---
---



@InProceedings{pmlr-v80-hartford18a,
  title = 	 {Deep Models of Interactions Across Sets},
  author =       {Hartford, Jason and Graham, Devon and Leyton-Brown, Kevin and Ravanbakhsh, Siamak},
  booktitle = 	 {Proceedings of the 35th International Conference on Machine Learning},
  pages = 	 {1909--1918},
  year = 	 {2018},
  editor = 	 {Dy, Jennifer and Krause, Andreas},
  volume = 	 {80},
  preview={exchangable.gif},
  bibtex_show = {True},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {<i>(Joint first author)</i>},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v80/hartford18a/hartford18a.pdf},
  url = 	 {https://proceedings.mlr.press/v80/hartford18a.html},
  abstract = 	 {We use deep learning to model interactions across two or more sets of objects, such as user{–}movie ratings or protein{–}drug bindings. The canonical representation of such interactions is a matrix (or tensor) with an exchangeability property: the encoding’s meaning is not changed by permuting rows or columns. We argue that models should hence be Permutation Equivariant (PE): constrained to make the same predictions across such permutations. We present a parameter-sharing scheme and prove that it is maximally expressive under the PE constraint. This scheme yields three benefits. First, we demonstrate performance competitive with the state of the art on multiple matrix completion benchmarks. Second, our models require a number of parameters independent of the numbers of objects and thus scale well to large datasets. Third, models can be queried about new objects that were not available at training time, but for which interactions have since been observed. We observed surprisingly good generalization performance on this matrix extrapolation task, both within domains (e.g., new users and new movies drawn from the same distribution used for training) and even across domains (e.g., predicting music ratings after training on movie ratings).}
}

@inproceedings{NEURIPS2020_993edc98,
 author = {Hartford, Jason and Leyton-Brown, Kevin and Raviv, Hadas and Padnos, Dan and Lev, Shahar and Lenz, Barak},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Larochelle and M. Ranzato and R. Hadsell and M.F. Balcan and H. Lin},
 preview = {egal.gif},
 pages = {13163--13173},
 bibtex_show = {True},
 month = 	 {;},
 publisher = {Curran Associates, Inc.},
 title = {Exemplar Guided Active Learning},
 pdf = {https://proceedings.neurips.cc/paper/2020/file/993edc98ca87f7e08494eec37fa836f7-Paper.pdf},
 volume = {33},
 year = {2020}
}

@misc{ahuja2022sparse,
  doi = {10.48550/ARXIV.2206.01101},
  bibtex_show = {True},
  url = {https://arxiv.org/abs/2206.01101},
  pdf = {220601101.pdf},
  selected={true},
  author = {Ahuja, Kartik and Hartford, Jason and Bengio, Yoshua},
  month = {;},
  preview={sparse.gif},
  abstract = {The theory of representation learning aims to build methods that provably invert the data generating process with minimal domain knowledge or any source of supervision. Most prior approaches require strong distributional assumptions on the latent variables and weak supervision (auxiliary information such as timestamps) to provide provable identification guarantees. In this work, we show that if one has weak supervision from observations generated by sparse perturbations of the latent variables--e.g. images in a reinforcement learning environment where actions move individual sprites--identification is achievable under unknown continuous latent distributions. We show that if the perturbations are applied only on mutually exclusive blocks of latents, we identify the latents up to those blocks. We also show that if these perturbation blocks overlap, we identify latents up to the smallest blocks shared across perturbations. Consequently, if there are blocks that intersect in one latent variable only, then such latents are identified up to permutation and scaling. We propose a natural estimation procedure based on this theory and illustrate it on low-dimensional synthetic and image-based experiments.},
  keywords = {Machine Learning (cs.LG), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Weakly Supervised Representation Learning with Sparse Perturbations},
  
  publisher = {arXiv},
  
  year = {2022},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}


 @phdthesis{Hartford_2021,
 bibtex_show = {True}, 
 series={Electronic Theses and Dissertations (ETDs) 2008+}, 
 title={Architectures and learning algorithms for data-driven decision making (PhD thesis)},
 url={https://open.library.ubc.ca/collections/ubctheses/24/items/1.0397441}, 
 pdf={ubc_2021_november_hartford_jason.pdf},
 abstract={To design good policy, we need accurate models of how the decision makers that operate within a given system will respond to policy changes. For example, an economist reasoning about the design of an auction needs a model of human behavior in order to predict how changes to the auction design will be reflected in outcomes; or a doctor deciding on treatments needs a model of people's health responses under different treatments to select the best treatment policy. We would like to leverage the accuracy of modern deep learning approaches to estimate these models, but this setting brings two non-standard challenges. First, decision problems often involve reasoning over sets of items, so we need deep networks that reflect this structure. The first part of this thesis develops a deep network layer that reflects this structural assumption, and shows that the resulting layer is maximally expressive among parameter tying schemes. We then evaluate deep network architectures composed of these layers on a variety of decision problems from human decision making in a game theory setting, to algorithmic decision making on propositional satisfiability problems. The second challenge is that predicting the effect of policy changes involves reasoning about shifts in distribution: any policy change will, by definition, change the conditions under which decision makers operate. This violates the standard machine learning assumption that models will be evaluated under the same conditions as those under which they were trained (the ``independent and identically distributed'' data assumption). The second part of this thesis shows how we can train deep networks that make valid predictions of the results of such policy interventions, by adapting the classical causal inference method of instrumental variables. Finally, we develop methods that are robust to some violations of the instrumental variable assumptions in settings with multiple instrumental variables.},
 DOI={http://dx.doi.org/10.14288/1.0397441}, 
 school={University of British Columbia}, 
 author={Hartford, Jason Siyanda}, 
 year={2021}, 
 month = {;},
 collection={Electronic Theses and Dissertations (ETDs) 2008+}}


@article{Cameron_Hartford_Lundy_Leyton-Brown_2022,
bibtex_show = {True}, 
title={The Perils of Learning Before Optimizing}, 
volume={36},
preview={perils.jpeg},
pdf={perils.pdf},
url={https://ojs.aaai.org/index.php/AAAI/article/view/20284}, 
DOI={10.1609/aaai.v36i4.20284}, 
abstract={Formulating real-world optimization problems often begins with making predictions from historical data (e.g., an optimizer that aims to recommend fast routes relies upon travel-time predictions). Typically, learning the prediction model used to generate the optimization problem and solving that problem are performed in two separate stages. Recent work has showed how such prediction models can be learned end-to-end by differentiating through the optimization task. Such methods often yield empirical improvements, which are typically attributed to end-to-end making better error tradeoffs than the standard loss function used in a two-stage solution. We refine this explanation and more precisely characterize when end-to-end can improve performance. When prediction targets are stochastic, a two-stage solution must make an a priori choice about which statistics of the target distribution to model---we consider expectations over prediction targets---while an end-to-end solution can make this choice adaptively. We show that the performance gap between a two-stage and end-to-end approach is closely related to the \emph{price of correlation} concept in stochastic optimization and show the implications of some existing POC results for the predict-then-optimize problem. We then consider a novel and particularly practical setting, where multiple prediction targets are combined to obtain each of the objective function’s coefficients. We give explicit constructions where (1) two-stage performs unboundedly worse than end-to-end; and (2) two-stage is optimal. We use simulations to experimentally quantify performance gaps and identify a wide range of real-world applications from the literature whose objective functions rely on multiple prediction targets, suggesting that end-to-end learning could yield significant improvements.}, 
number={4}, 
journal={Proceedings of the AAAI Conference on Artificial Intelligence}, 
author={Cameron, Chris and Hartford, Jason and Lundy, Taylor and Leyton-Brown, Kevin}, 
year={2022}, 
month={;}, 
pages={3708-3715} }

@inproceedings{
layne2022leveraging,
bibtex_show = {True},
title={Leveraging Structure Between Environments: Phylogenetic Regularization Incentivizes Disentangled Representations},
author={Elliot Layne and Dhanya Sridhar and Jason Hartford and Mathieu Blanchette},
booktitle={UAI 2022 Workshop on Causal Representation Learning},
abstract={Recently, learning invariant predictors across varying environments has been shown to improve the generalization of supervised learning methods. This line of investigation holds great potential for application to biological problem settings, where data is often naturally heterogeneous. Biological samples  often originate from different distributions, or environments. However, in biological contexts, the standard "invariant prediction" setting may not completely fit: the optimal predictor may in fact vary across biological environments. There also exists strong domain knowledge about the relationships between environments, such as the evolutionary history of a set of species, or the differentiation process of cell types. Most work on generic invariant predictors have not assumed the existence of structured relationships between environments. However, this prior knowledge about environments themselves has already been shown to improve prediction through a particular form of regularization applied when learning a set of predictors. In this work, we empirically evaluate whether a regularization strategy that exploits environment-based prior information can be used to learn representations that better disentangle causal factors that generate observed data.  We find evidence that these methods do in fact improve the disentanglement of latent embeddings. We also show a setting where these methods can leverage phylogenetic information to estimate the number of latent causal features.},
year={2022},
url={https://openreview.net/forum?id=ilGixSIzaa6}
}

@inproceedings{
ahuja2022properties,
bibtex_show = {True},
selected={true},
preview={balls.gif},
pdf={properties.pdf},
month={; <b><i>(Joint first author)</i>, Spotlight presentation</b>;},
abstract={A key goal of unsupervised representation learning is "inverting" a data generating process to recover its latent properties. Existing work that provably achieves this goal relies on strong assumptions on relationships between the latent variables (e.g., independence conditional on auxiliary information). In this paper, we take a very different perspective on the problem and ask, "Can we instead identify latent properties by leveraging knowledge of the mechanisms that govern their evolution?" We provide a complete characterization of the sources of non-identifiability as we vary knowledge about a set of possible mechanisms. In particular, we prove that if we know the exact mechanisms under which the latent properties evolve, then identification can be achieved up to any equivariances that are shared by the underlying mechanisms. We generalize this characterization to settings where we only know some hypothesis class over possible mechanisms, as well as settings where the mechanisms are stochastic. We demonstrate the power of this mechanism-based perspective by showing that we can leverage our results to generalize existing identifiable representation learning results. These results suggest that by exploiting inductive biases on mechanisms, it is possible to design a range of new identifiable representation learning approaches.},
title={Properties from mechanisms: an equivariance perspective on identifiable representation learning},
author={Kartik Ahuja and Jason Hartford and Yoshua Bengio},
booktitle={International Conference on Learning Representations},
year={2022},
url={https://openreview.net/forum?id=g5ynW-jMq4M}
}


@inproceedings{NIPS2016_7eb3c8be,
	author = {Hartford, Jason and Wright, James R and Leyton-Brown, Kevin},
  bibtex_show = {True},
	booktitle = {Advances in Neural Information Processing Systems},
	editor = {D. Lee and M. Sugiyama and U. Luxburg and I. Guyon and R. Garnett},
	publisher = {Curran Associates, Inc.},
  preview={gamenet.gif},
  pdf = {NIPS-2016-deep-learning-for-predicting-human-strategic-behavior-Paper.pdf},
  abstract = {Predicting the behavior of human participants in strategic settings is an important problem in many domains. Most existing work either assumes that participants are perfectly rational, or attempts to directly model each participant's cognitive processes based on insights from cognitive psychology and experimental economics. In this work, we present an alternative, a deep learning approach that automatically performs cognitive modeling without relying on such expert knowledge. We introduce a novel architecture that allows a single network to generalize across different input and output dimensions by using matrix units rather than scalar units, and show that its performance significantly outperforms that of the previous state of the art, which relies on expert-constructed features.},
	title = {Deep Learning for Predicting Human Strategic Behavior},
	url = {https://proceedings.neurips.cc/paper/2016/file/7eb3c8be3d411e8ebfab08eba5f49632-Paper.pdf},
	volume = {29},
	year = {2016},
	bdsk-url-1 = {https://proceedings.neurips.cc/paper/2016/file/7eb3c8be3d411e8ebfab08eba5f49632-Paper.pdf}}


@InProceedings{pmlr-v139-hartford21a,
  title = 	 {Valid Causal Inference with (Some) Invalid Instruments},
  author =       {Hartford, Jason and Veitch, Victor and Sridhar, Dhanya and Leyton-Brown, Kevin},
  booktitle = 	 {Proceedings of the 38th International Conference on Machine Learning},
  pages = 	 {4096--4106},
  preview={modeiv.gif},
  year = 	 {2021},
  bibtex_show = {True},
  selected={true},
  editor = 	 {Meila, Marina and Zhang, Tong},
  volume = 	 {139},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {18--24 Jul},
  publisher =    {PMLR},
  pdf = 	 {hartford21a.pdf},
  url = 	 {https://proceedings.mlr.press/v139/hartford21a.html},
  abstract = 	 {Instrumental variable methods provide a powerful approach to estimating causal effects in the presence of unobserved confounding. But a key challenge when applying them is the reliance on untestable "exclusion" assumptions that rule out any relationship between the instrument variable and the response that is not mediated by the treatment. In this paper, we show how to perform consistent IV estimation despite violations of the exclusion assumption. In particular, we show that when one has multiple candidate instruments, only a majority of these candidates—or, more generally, the modal candidate-response relationship—needs to be valid to estimate the causal effect. Our approach uses an estimate of the modal prediction from an ensemble of instrumental variable estimators. The technique is simple to apply and is "black-box" in the sense that it may be used with any instrumental variable estimator as long as the treatment effect is identified for each valid instrument independently. As such, it is compatible with recent machine-learning based estimators that allow for the estimation of conditional average treatment effects (CATE) on complex, high dimensional data. Experimentally, we achieve accurate estimates of conditional average treatment effects using an ensemble of deep network-based estimators, including on a challenging simulated Mendelian Randomization problem.}
}

@InProceedings{pmlr-v70-hartford17a,
  title = 	 {Deep {IV}: A Flexible Approach for Counterfactual Prediction},
  author =       {Jason Hartford and Greg Lewis and Kevin Leyton-Brown and Matt Taddy},
  booktitle = 	 {Proceedings of the 34th International Conference on Machine Learning},
  pages = 	 {1414--1423},
  year = 	 {2017},
  selected={true},
  editor = 	 {Precup, Doina and Teh, Yee Whye},
  volume = 	 {70},
  preview={deepiv.gif},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {06--11 Aug},
  publisher =    {PMLR},
  bibtex_show = {True},

  pdf = 	 {http://proceedings.mlr.press/v70/hartford17a/hartford17a.pdf},
  url = 	 {https://proceedings.mlr.press/v70/hartford17a.html},
  abstract = 	 {Counterfactual prediction requires understanding causal relationships between so-called treatment and outcome variables. This paper provides a recipe for augmenting deep learning methods to accurately characterize such relationships in the presence of instrument variables (IVs) – sources of treatment randomization that are conditionally independent from the outcomes. Our IV specification resolves into two prediction tasks that can be solved with deep neural nets: a first-stage network for treatment prediction and a second-stage network whose loss function involves integration over the conditional treatment distribution. This Deep IV framework allows us to take advantage of off-the-shelf supervised learning techniques to estimate causal effects by adapting the loss function. Experiments show that it outperforms existing machine learning approaches.}
}



@article{Cameron_Chen_Hartford_Leyton-Brown_2020, 
title={Predicting Propositional Satisfiability via End-to-End Learning}, 
volume={34}, 
bibtex_show = {True},
url={https://ojs.aaai.org/index.php/AAAI/article/view/5733}, 
preview={pred_sat.gif},
DOI={10.1609/aaai.v34i04.5733}, 
abstractNote={&lt;p&gt;Strangely enough, it is possible to use machine learning models to predict the satisfiability status of hard SAT problems with accuracy considerably higher than random guessing. Existing methods have relied on extensive, manual feature engineering and computationally complex features (e.g., based on linear programming relaxations). We show for the first time that even better performance can be achieved by end-to-end learning methods — i.e., models that map directly from raw problem inputs to predictions and take only linear time to evaluate. Our work leverages deep network models which capture a key invariance exhibited by SAT problems: satisfiability status is unaffected by reordering variables and clauses. We showed that end-to-end learning with deep networks can outperform previous work on random 3-SAT problems at the solubility phase transition, where: (1) exactly 50% of problems are satisfiable; and (2) empirical runtimes of known solution methods scale exponentially with problem size (e.g., we achieved 84% prediction accuracy on 600-variable problems, which take hours to solve with state-of-the-art methods). We also showed that deep networks can generalize across problem sizes (e.g., a network trained only on 100-variable problems, which typically take about 10 ms to solve, achieved 81% accuracy on 600-variable problems).&lt;/p&gt;}, number={04}, journal={Proceedings of the AAAI Conference on Artificial Intelligence}, author={Cameron, Chris and Chen, Rex and Hartford, Jason and Leyton-Brown, Kevin}, year={2020}, month={Apr.}, pages={3324-3331} }